{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb8e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a320ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9bf11c37f2402cb38fafc30b70188f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419fcc2d722f468ab4bb13f719f035ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/109 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb52820ff69c4870bbf505a10521f721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Djvue/go-test-rl/commit/cf4a200fcab95e121db82ae944fbcd4195844161', commit_message='Upload dataset', commit_description='', oid='cf4a200fcab95e121db82ae944fbcd4195844161', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Djvue/go-test-rl', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Djvue/go-test-rl'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_from_disk('data/final_ds').push_to_hub('Djvue/go-test-rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a7866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7357cc8bb7da4cfd882355158c25e403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/6486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b21a02354f44859bd514959fc88dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/109274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_path': '52bdf3787c11b0237f5e7864c98b1d0e75af9eb9/revision/',\n",
       " 'relative_path': 'main.go',\n",
       " 'content': b'package main\\n\\nimport (\\n\\t\"errors\"\\n\\t\"fmt\"\\n\\t\"io/ioutil\"\\n\\t\"os\"\\n)\\n\\ntype Node struct {\\n\\tdata byte\\n\\tnext *Node\\n}\\n\\ntype Stack struct {\\n\\thead   *Node\\n\\tLength int\\n}\\n\\n// pushes a new element to the stack\\nfunc (s *Stack) Push(element byte) {\\n\\tnode := Node{data: element, next: nil}\\n\\tif s.head != nil {\\n\\t\\ttemp := s.head\\n\\t\\tnode.next = temp\\n\\t}\\n\\ts.head = &node\\n\\ts.Length++\\n}\\n\\n// removes the last added element from the stack\\nfunc (s *Stack) Pop() {\\n\\tif s.head != nil {\\n\\t\\ttemp := s.head.next\\n\\t\\ts.head = temp\\n\\t\\ts.Length--\\n\\t}\\n}\\n\\n// returns a pointer to empty stack\\nfunc NewStack() *Stack {\\n\\treturn &Stack{\\n\\t\\tnil,\\n\\t\\t0,\\n\\t}\\n}\\n\\n// receives a string slice where each index must be\\n// written to the filename file\\nfunc writeToRevisionFile(strSlice []string, filename string) error {\\n\\tfile, err := os.Create(filename)\\n\\tif err != nil {\\n\\t\\treturn err\\n\\t}\\n\\tdefer file.Close()\\n\\tfor idx, str := range strSlice {\\n\\t\\tif idx == len(strSlice)-1 {\\n\\t\\t\\t// do not add new line to last line\\n\\t\\t\\tfile.WriteString(str)\\n\\t\\t} else {\\n\\t\\t\\tfile.WriteString(str + \"\\\\n\")\\n\\t\\t}\\n\\t}\\n\\n\\treturn nil\\n}\\n\\n// return the working dir concatened to the file passed\\n// in the command line\\nfunc getFullPath(fileName string) (string, error) {\\n\\t//from where i am calling the program\\n\\tworkingDir, err := os.Getwd()\\n\\tif err != nil {\\n\\t\\treturn \"\", errors.New(\"Invalid working dir\")\\n\\t}\\n\\n\\treturn workingDir + \"/\" + fileName, nil\\n}\\n\\n// returns the file name given in the command line\\nfunc getFileName() (string, error) {\\n\\tif len(os.Args) < 2 {\\n\\t\\treturn \"\", errors.New(\"You need to pass the name of one file\")\\n\\t}\\n\\tfileName := os.Args[1]\\n\\n\\treturn fileName, nil\\n}\\n\\n// returns a slice of strings where each index\\n// is a word that was marked as bold\\nfunc getBold(lines []byte) []string {\\n\\tvar boldWords []string\\n\\tstack := NewStack()\\n\\tvar currentWord []byte\\n\\tfor _, char := range lines {\\n\\t\\tif char == \\'*\\' {\\n\\t\\t\\tif stack.Length == 3 {\\n\\t\\t\\t\\tboldWords = append(boldWords, string(currentWord))\\n\\t\\t\\t\\tstack = NewStack()\\n\\t\\t\\t\\tcurrentWord = []byte{}\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tstack.Push(char)\\n\\t\\t\\t}\\n\\t\\t} else {\\n\\t\\t\\tif stack.Length == 2 {\\n\\t\\t\\t\\tcurrentWord = append(currentWord, char)\\n\\t\\t\\t} else if stack.Length == 1 {\\n\\t\\t\\t\\t// if the previous was a * but the current is not\\n\\t\\t\\t\\t// means we are trying to bold the word\\n\\t\\t\\t\\tstack = NewStack()\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n\\n\\treturn boldWords\\n}\\n\\nfunc main() {\\n\\tfileName, err := getFileName()\\n\\tif err != nil {\\n\\t\\tfmt.Printf(\"Error getting filename %v\\\\n\", err)\\n\\t\\treturn\\n\\t}\\n\\n\\tfilePath, err := getFullPath(fileName)\\n\\tif err != nil {\\n\\t\\tfmt.Printf(\"Error getting working dir %v\\\\n\", err)\\n\\t\\treturn\\n\\t}\\n\\tlines, err := ioutil.ReadFile(filePath)\\n\\tif err != nil {\\n\\t\\tfmt.Printf(\"Error reading markdown file\")\\n\\t\\treturn\\n\\t}\\n\\n\\tboldWords := getBold(lines)\\n\\twriteToRevisionFile(boldWords, \"revision\")\\n}\\n'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_from_disk('data/final_ds')\n",
    "\n",
    "projects = ds.unique('project_path')\n",
    "projects_ds = datasets.Dataset.from_dict({'project_path': projects})\n",
    "\n",
    "def project_files(row):\n",
    "    project_path = row['project_path'][0]\n",
    "    pathlist = Path('data/repos/'+project_path).glob('**/*')\n",
    "    out = {\n",
    "        'project_path': [],\n",
    "        'relative_path': [],\n",
    "        'content': [],\n",
    "    }\n",
    "    for path in pathlist:\n",
    "        if not path.is_file():\n",
    "            continue\n",
    "        relative_path = str(path)[len('data/repos/'+project_path):]\n",
    "        content = path.read_bytes()\n",
    "        out['project_path'].append(project_path)\n",
    "        out['relative_path'].append(relative_path)\n",
    "        out['content'].append(content)\n",
    "    return out\n",
    "\n",
    "files_ds = projects_ds.map(project_files, batched=True, batch_size=1, num_proc=32)\n",
    "\n",
    "files_ds.save_to_disk('data/final_files_ds')\n",
    "\n",
    "print(len(files_ds))\n",
    "files_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03006057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95de3d248ab4be1afd888588b772fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf803c55b564ad4aa48e08d4e5e9d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/547 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f75463ff1bf4fd1b341b0ce166780cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/547 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Djvue/go-test-rl-files/commit/085eced172c39a492677b1760a3d079a04c09195', commit_message='Upload dataset', commit_description='', oid='085eced172c39a492677b1760a3d079a04c09195', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Djvue/go-test-rl-files', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Djvue/go-test-rl-files'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_from_disk('data/final_files_ds').push_to_hub('Djvue/go-test-rl-files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18fcba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 17:53:21.265067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748184801.376042    7669 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748184801.409239    7669 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748184801.671795    7669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748184801.671852    7669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748184801.671858    7669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748184801.671862    7669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-25 17:53:21.701896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a64802530146c29e52ee30f89806a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/588M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Djvue/go-test-rl/commit/935902c51ab312156d89f845d18e5f8d638ebe75', commit_message='Upload LlamaForCausalLM', commit_description='', oid='935902c51ab312156d89f845d18e5f8d638ebe75', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Djvue/go-test-rl', endpoint='https://huggingface.co', repo_type='model', repo_id='Djvue/go-test-rl'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    'data/model_12',\n",
    "    device_map=\"cpu\",\n",
    "    trust_remote_code=True,\n",
    ").push_to_hub('Djvue/go-test-rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d61ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
